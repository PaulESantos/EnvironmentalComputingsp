---
weight: 7
title: "Power Analyses"
output: html_document
aliases: /power-analysis/
---



<div id="qué-es-el-análisis-de-potencia-y-por-qué-es-importante" class="section level3">
<h3>¿Qué es el análisis de potencia y por qué es importante?</h3>
<p>Recopilas datos para responder una pregunta, generalmente con el objetivo de detectar un efecto particular (por ejemplo, efecto del tratamiento). La potencia de tu prueba es <em>la probabilidad de detectar un efecto (es decir, obtener un valor p &lt; 0.05) con el diseño experimental que tienes y el tamaño de efecto que esperas o consideras significativo</em>.</p>
<p>Comenzaré simulando un conjunto de datos que tiene un efecto (una diferencia entre el grupo de control y el grupo de tratamiento), y veremos si podemos detectar el efecto. Realizaremos una simple <a href="../t-tests/two-sample-t-test">prueba t de dos muestras</a> como ejemplo.</p>
<pre class="r"><code>set.seed(1)

N &lt;- 20 # the sample size

trt.effect &lt;- 0.2 # difference between control and treatment means
sigma &lt;- 0.5 # standard deviation of control and treatment groups

mean.con &lt;- 0 # mean of control group

mean.trt &lt;- mean.con + trt.effect # mean of treatment group

control &lt;- rnorm(N, mean.con, sigma) # 20 data points for the control group taken from a normal distribution with known sample size, mean and s.d.

treatment &lt;- rnorm(N, mean.trt, sigma) # data for the treatment group

t.test(control, treatment)</code></pre>
<pre><code>## 
## 	Welch Two Sample t-test
## 
## data:  control and treatment
## t = -0.71923, df = 37.917, p-value = 0.4764
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.3872163  0.1842117
## sample estimates:
##  mean of x  mean of y 
## 0.09526194 0.19676424</code></pre>
<p>Podemos ver las diferencias entre los grupos con un diagrama de caja y probar esas diferencias con una prueba t:</p>
<pre class="r"><code>boxplot(cbind(control, treatment))</code></pre>
<p><img src="/Statistics/power-analysis/_index_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<pre class="r"><code>t.test(control, treatment)</code></pre>
<pre><code>## 
## 	Welch Two Sample t-test
## 
## data:  control and treatment
## t = -0.71923, df = 37.917, p-value = 0.4764
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.3872163  0.1842117
## sample estimates:
##  mean of x  mean of y 
## 0.09526194 0.19676424</code></pre>
<p>Sabemos que hay un efecto del tratamiento, con un tamaño de efecto de 0.2, pero la prueba no pudo detectarlo. Esto se conoce como error de tipo II. Repitamos el mismo experimento con exactamente la misma configuración.</p>
<pre class="r"><code>#
set.seed(3)
N &lt;- 20
trt.effect &lt;- 0.2
sigma &lt;- 0.5
mean.con &lt;- 0
mean.trt &lt;- mean.con + trt.effect
control &lt;- rnorm(N, mean.con, sigma)
treatment &lt;- rnorm(N, mean.trt, sigma)
boxplot(cbind(control, treatment))</code></pre>
<p><img src="/Statistics/power-analysis/_index_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<pre class="r"><code>t.test(control, treatment)</code></pre>
<pre><code>## 
## 	Welch Two Sample t-test
## 
## data:  control and treatment
## t = -2.3471, df = 37.416, p-value = 0.02432
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.57817515 -0.04253493
## sample estimates:
##   mean of x   mean of y 
## -0.08359522  0.22675982</code></pre>
<p>Esta vez detectamos un efecto. Esto siempre ocurre, sin importar cuál sea tu diseño experimental, si hay un efecto presente, tienes alguna posibilidad de detectarlo, esto se llama potencia. Para no perder tiempo y dinero, solo debemos realizar experimentos que tengan alta potencia, es decir, alta probabilidad de detectar un efecto si existe. Podemos calcular la potencia de este experimento.</p>
</div>
<div id="análisis-de-potencia-simple-con-pwr" class="section level3">
<h3>Análisis de potencia simple con ‘pwr’</h3>
<p>Existen varios paquetes que realizan análisis de potencia en R. <a href="https://cran.r-project.org/web/packages/pwr/index.html">pwr</a> realiza cosas simples hasta <code>lm</code> y <a href="https://cran.r-project.org/web/packages/simr/index.html">simR</a> realiza modelos más complejos <a href="../mixed-models">modelos mixtos</a> y <a href="../glms">glms</a>.</p>
<p>Primero, descarga e instala el paquete.</p>
<pre class="r"><code>library(pwr)</code></pre>
<p>Para realizar cálculos de potencia en pwr, debes dejar uno de los valores como NULL y completar los demás. Luego te proporcionará el valor para el que dejaste en blanco.</p>
<p>Aquí usaré la función <code>pwr.t.test</code> y dejaré en blanco el valor de potencia. Calculará la potencia para el diseño experimental dado el tamaño de muestra y el tamaño de efecto especificados. Ten cuidado; la variable d, que en el archivo de ayuda se llama tamaño de efecto, es nuestro efecto de tratamiento (diferencia entre medias) dividido por la desviación estándar.</p>
<pre class="r"><code>pwr.t.test(n = 20, d = trt.effect / sigma, sig.level = 0.05, power = NULL)</code></pre>
<pre><code>## 
##      Two-sample t test power calculation 
## 
##               n = 20
##               d = 0.4
##       sig.level = 0.05
##           power = 0.2343494
##     alternative = two.sided
## 
## NOTE: n is number in *each* group</code></pre>
<p>¡Ups! La potencia es solo del 25%. Esto significa que, dado el efecto que esperamos y con este tamaño de muestra, solo detectaremos ese efecto el 25% del tiempo. Entonces, probablemente no valga la pena hacer este experimento. Podríamos aumentar el tamaño de muestra para aumentar la potencia.</p>
<p>Ahora podemos utilizar nuestros cálculos de potencia para determinar qué tamaño de muestra nos dará una buena potencia, siendo el 80% el umbral habitual. Repetimos el cálculo pero ahora dejando en blanco la variable N y estableciendo la potencia en 0.8.</p>
<pre class="r"><code>pwr.t.test(n = NULL, d = trt.effect / sigma, sig.level = 0.05, power = 0.8)</code></pre>
<pre><code>## 
##      Two-sample t test power calculation 
## 
##               n = 99.08032
##               d = 0.4
##       sig.level = 0.05
##           power = 0.8
##     alternative = two.sided
## 
## NOTE: n is number in *each* group</code></pre>
<p>Esto nos indica que necesitamos un tamaño de muestra (para cada grupo) de 100 para lograr una potencia del 80% para detectar nuestro efecto. Esto obviamente es importante saberlo si las medidas replicadas son costosas o requieren mucho tiempo para recopilar.</p>
<p>También podemos trazar la potencia para varios tamaños de muestra. Aquí tienes un código que calcula y traza la potencia para tamaños de muestra desde 2 hasta 200.</p>
<pre class="r"><code>nvals &lt;- seq(2, 200, length.out = 200)
powvals &lt;- sapply(nvals, function(x) pwr.2p.test(h = trt.effect / sigma, n = x, sig.level = 0.05)$power)

plot(nvals, powvals,
  xlab = &quot;sample size&quot;, ylab = &quot;power&quot;,
  main = &quot;Power curve for sample size for difference in proportions&quot;,
  lwd = 2, col = &quot;red&quot;, type = &quot;l&quot;
)

abline(h = 0.8)</code></pre>
<p><img src="/Statistics/power-analysis/_index_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>El paquete <em>pwr</em> tiene varias funciones, pero todas funcionan de manera similar.</p>
<table>
<thead>
<tr class="header">
<th>Función</th>
<th>Descripción</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>pwr.2p.test</code></td>
<td>dos proporciones (n iguales)</td>
</tr>
<tr class="even">
<td><code>pwr.2p2n.test</code></td>
<td>dos proporciones (n desiguales)</td>
</tr>
<tr class="odd">
<td><code>pwr.anova.test</code></td>
<td>ANOVA de un factor equilibrado</td>
</tr>
<tr class="even">
<td><code>pwr.chisq.test</code></td>
<td>prueba de chi-cuadrado</td>
</tr>
<tr class="odd">
<td><code>pwr.f2.test</code></td>
<td>modelo lineal general</td>
</tr>
<tr class="even">
<td><code>pwr.p.test</code></td>
<td>proporción (una muestra)</td>
</tr>
<tr class="odd">
<td><code>pwr.r.test</code></td>
<td>correlación</td>
</tr>
<tr class="even">
<td><code>pwr.t.test</code></td>
<td>pruebas t (una muestra, dos muestras, emparejadas)</td>
</tr>
<tr class="odd">
<td><code>pwr.t2n.test</code></td>
<td>prueba t (dos muestras con n desiguales)</td>
</tr>
</tbody>
</table>
<p>Generalmente es un poco complicado especificar el tamaño de efecto, puedes encontrar una buena guía para este paquete <a href="http://www.statmethods.net/stats/power.html">aquí</a>.</p>
<p>Ten en cuenta que especificar el tamaño de efecto no es una pregunta estadística, es una pregunta ecológica sobre qué tamaño de efecto es significativo para tu estudio en particular. Por ejemplo, ¿quieres poder detectar una disminución del 10% en la abundancia de un animal raro o te conformarías con un diseño de muestreo capaz de detectar una disminución del 25%?</p>
</div>
<div id="análisis-con-modelos-lineales-y-mixtos-con-simr" class="section level3">
<h3>Análisis con modelos lineales y mixtos con ‘simr’</h3>
<p>Si estás llevando a cabo un experimento con factores aleatorios y necesitas realizar un <a href="../mixed-models/">modelo mixto</a> y tu análisis de potencia debe reflejar eso, esto es mucho más complicado que los ejemplos anteriores y deberemos utilizar métodos de simulación. El paquete <a href="https://cran.r-project.org/web/packages/simr/index.html">simR</a> está diseñado para esto.</p>
<p>Descarga e instala el paquete.</p>
<pre class="r"><code>library(simr)
simrOptions(progress = FALSE)</code></pre>
<p><strong>Análisis de potencia con un estudio piloto.</strong>
Hemos realizado un estudio piloto y ahora queremos decidir cómo asignar el muestreo para el estudio completo. El estudio busca un efecto de la modificación del estuario en la abundancia de una especie marina. Supongamos que tenemos los recursos para realizar un máximo de 72 muestras y queremos maximizar la potencia para una prueba de la variable categórica ‘modificación’.</p>
<p><img src="Mixed_models_1_image.jpg" /></p>
<p>Tenemos un conjunto de datos piloto ‘pilot’ que tiene un efecto fijo continuo de la temperatura, un efecto fijo de la modificación y un efecto aleatorio para el sitio (anidado dentro de la modificación). La variable de respuesta es la abundancia de una especie de interés.</p>
<p>Descarga estos datos piloto, <a href="/datasets/Pilot.csv">Pilot.csv</a>, impórtalos en R y cambia la variable de modificación a un factor (etiquetado como 1, 2 y 3, pero no como un entero).</p>
<pre class="r"><code>Pilot &lt;- read.csv(file = &quot;Pilot.csv&quot;, header = TRUE)
Pilot$modification &lt;- factor(Pilot$modification)</code></pre>
<p>Graficar la abundancia en función del sitio y los niveles del factor de modificación nos muestra que tenemos datos donde los sitios varían bastante dentro de cada modificación.</p>
<pre class="r"><code>par(mfrow = c(1, 2))
boxplot(abundance ~ modification, data = Pilot, main = &quot;modification&quot;)
boxplot(abundance ~ site, data = Pilot, main = &quot;site&quot;)</code></pre>
<p><img src="/Statistics/power-analysis/_index_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p>Estos datos de conteo con un efecto aleatorio de sitio se modelan mejor con un <a href="../mixed-models/mixed-model-3">modelo lineal mixto generalizado</a> utilizando <code>glmer</code> del paquete lme4.</p>
<pre class="r"><code>library(lme4)

Pilot.mod &lt;- glmer(abundance ~ temperature + modification + (1 | site), family = &quot;poisson&quot;, data = Pilot)

summary(Pilot.mod)</code></pre>
<pre><code>## Generalized linear mixed model fit by maximum likelihood (Laplace
##   Approximation) [glmerMod]
##  Family: poisson  ( log )
## Formula: abundance ~ temperature + modification + (1 | site)
##    Data: Pilot
## 
##      AIC      BIC   logLik deviance df.resid 
##    153.3    157.7    -71.6    143.3       13 
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -1.2983 -0.4266  0.1293  0.4240  0.8410 
## 
## Random effects:
##  Groups Name        Variance Std.Dev.
##  site   (Intercept) 0.006274 0.07921 
## Number of obs: 18, groups:  site, 6
## 
## Fixed effects:
##               Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)    1.69024    0.09851   17.16   &lt;2e-16 ***
## temperature    4.08409    0.08875   46.02   &lt;2e-16 ***
## modification2  1.14103    0.09465   12.05   &lt;2e-16 ***
## modification3  2.39503    0.09538   25.11   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr) tmprtr mdfct2
## temperature -0.692              
## modificatn2 -0.558  0.023       
## modificatn3 -0.696  0.226  0.565</code></pre>
<p>Hay dos coeficientes que especifican los efectos de la modificación (ya que hay tres categorías de modificación). Para realizar un análisis de potencia, debemos especificar tamaños de efecto que sean ecológicamente significativos. Ten en cuenta que estos están en la escala del modelo, para un modelo <code>poisson</code> están en la escala logarítmica (y multiplicativos).</p>
<pre class="r"><code>fixef(Pilot.mod)[&quot;modification2&quot;] &lt;- 0.1
fixef(Pilot.mod)[&quot;modification3&quot;] &lt;- 0.2</code></pre>
<p>Ahora podemos usar la función <code>powerSim</code> para calcular la probabilidad de que un experimento con este tamaño de muestra pueda detectar un efecto de modificación, esto es la ‘potencia’. Quiero utilizar una prueba de razón de verosimilitudes (es decir, usar la función <code>anova</code>) para probar un efecto de modificación, así que lo especifico con el argumento <code>lr</code>.</p>
<pre class="r"><code>powerSim(Pilot.mod, fixed(&quot;modification&quot;, &quot;lr&quot;), nsim = 50)</code></pre>
<pre><code>## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)</code></pre>
<pre><code>## Power for predictor &#39;modification&#39;, (95% confidence interval):
##       46.00% (31.81, 60.68)
## 
## Test: Likelihood ratio
## 
## Based on 50 simulations, (0 warnings, 0 errors)
## alpha = 0.05, nrow = 18
## 
## Time elapsed: 0 h 0 m 8 s</code></pre>
<pre class="r"><code># this is a small number of sims for demonstration, the default of 1000 is more appropriate</code></pre>
<p>Así que esperamos tener un poder de alrededor del 45% para una prueba de razón de verosimilitud para ‘modificación’ con el número actual de observaciones. Esto es bastante bajo, nos gustaría ver un poder por encima del 80%, así que veamos cómo afecta el aumento del tamaño de la muestra.</p>
<p><strong>¿Cómo podemos aumentar el poder?</strong>
Aumentar las observaciones es deseable para aumentar el poder, pero en este diseño de muestreo, tenemos varias formas de agregar observaciones a tus datos. Podrías muestrear más sitios, pero mantener el número de muestras por sitio igual, o podrías mantener el número de sitios igual y muestrear más dentro de cada sitio.</p>
<pre class="r"><code>xtabs(~ modification + site, data = Pilot)</code></pre>
<pre><code>##             site
## modification a b c d e f
##            1 3 3 0 0 0 0
##            2 0 0 3 3 0 0
##            3 0 0 0 0 3 3</code></pre>
<p>Actualmente hay 2 sitios por categoría de modificación y 3 observaciones por sitio. Intentemos aumentar el número de sitios. Hacemos esto utilizando la función <code>extend</code> para explorar cómo afectará el aumento del tamaño de la muestra al poder. Al utilizar <code>along=site</code>, agregaremos más sitios. Con nuestro presupuesto de 72 observaciones y 3 observaciones por sitio, tendríamos 24 sitios.</p>
<pre class="r"><code>full1 &lt;- extend(Pilot.mod, along = &quot;site&quot;, n = 24)

xtabs(~site, data = attributes(full1)$newData)</code></pre>
<pre><code>## site
##  1 10 11 12 13 14 15 16 17 18 19  2 20 21 22 23 24  3  4  5  6  7  8  9 
##  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3</code></pre>
<pre class="r"><code>powerSim(full1, fixed(&quot;modification&quot;, &quot;lr&quot;), nsim = 50)</code></pre>
<pre><code>## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)</code></pre>
<pre><code>## Power for predictor &#39;modification&#39;, (95% confidence interval):
##       92.00% (80.77, 97.78)
## 
## Test: Likelihood ratio
## 
## Based on 50 simulations, (0 warnings, 0 errors)
## alpha = 0.05, nrow = 72
## 
## Time elapsed: 0 h 0 m 14 s</code></pre>
<p>Así que obtenemos alrededor del 90% de poder, suena genial. Para ver si agregar más observaciones por sitio haría que fuera mejor o peor, utilizamos el argumento <code>within</code>.</p>
<pre class="r"><code>full2 &lt;- extend(Pilot.mod, within = &quot;site&quot;, n = 12)

xtabs(~site, data = attributes(full2)$newData)</code></pre>
<pre><code>## site
##  a  b  c  d  e  f 
## 12 12 12 12 12 12</code></pre>
<pre class="r"><code>powerSim(full2, fixed(&quot;modification&quot;, &quot;lr&quot;), nsim = 50)</code></pre>
<pre><code>## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)</code></pre>
<pre><code>## Power for predictor &#39;modification&#39;, (95% confidence interval):
##       64.00% (49.19, 77.08)
## 
## Test: Likelihood ratio
## 
## Based on 50 simulations, (0 warnings, 0 errors)
## alpha = 0.05, nrow = 72
## 
## Time elapsed: 0 h 0 m 8 s</code></pre>
<p>Eso solo nos da alrededor del 60% de poder. Entonces, para estos datos, diseño de muestreo y pregunta, es mejor agregar más sitios. Por supuesto, también puedes hacer combinaciones, tal vez duplicar los sitios y duplicar las observaciones por sitio.</p>
<pre class="r"><code>full3 &lt;- extend(Pilot.mod, within = &quot;site&quot;, n = 6)
full3 &lt;- extend(full3, along = &quot;site&quot;, n = 12)

xtabs(~site, data = attributes(full3)$newData)</code></pre>
<pre><code>## site
##  1 10 11 12  2  3  4  5  6  7  8  9 
##  6  6  6  6  6  6  6  6  6  6  6  6</code></pre>
<pre class="r"><code>powerSim(full3, fixed(&quot;modification&quot;, &quot;lr&quot;), nsim = 50)</code></pre>
<pre><code>## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)
## boundary (singular) fit: see help(&#39;isSingular&#39;)</code></pre>
<pre><code>## Power for predictor &#39;modification&#39;, (95% confidence interval):
##       66.00% (51.23, 78.79)
## 
## Test: Likelihood ratio
## 
## Based on 50 simulations, (0 warnings, 0 errors)
## alpha = 0.05, nrow = 72
## 
## Time elapsed: 0 h 0 m 9 s</code></pre>
<p>Esto nos da un 75% de poder, que está a medio camino entre los otros. Entonces, en este caso, nuevamente es mejor agregar más sitios que más observaciones por sitio. Esto no siempre es cierto y depende en gran medida de la variabilidad dentro y entre sitios, de tu diseño experimental y de tu pregunta.</p>
</div>
<div id="algunas-notas" class="section level3">
<h3>Algunas notas</h3>
<p>El análisis de poder proporciona la probabilidad de detectar un efecto particular (de una determinada magnitud) a un nivel alfa particular (generalmente 0.05) si este efecto está presente. Si estás interesado en múltiples preguntas a partir de los mismos datos, para realizar un análisis de poder generalmente debes elegir una pregunta de interés principal.</p>
<p>Debes especificar el nivel del efecto que deseas poder detectar. Si utilizas el nivel estimado de un estudio piloto, esto se conoce como un cálculo de “poder observado” y no es un uso válido del análisis de poder.</p>
</div>
<div id="más-información" class="section level3">
<h3>Más información</h3>
<p><a href="https://cran.r-project.org/web/packages/simr/vignettes/examples.html">Algunos ejemplos adicionales de estudios piloto del paquete simR</a></p>
<p><a href="https://cran.r-project.org/web/packages/simr/vignettes/fromscratch.html">Análisis de poder desde cero sin estudio piloto</a></p>
<p>Más información sobre <a href="http://www.statmethods.net/stats/power.html">especificar el tamaño del efecto</a></p>
<p><strong>Autor</strong>: Gordana Popovic</p>
<p><strong>Año</strong>: 2016</p>
<p><strong>Última actualización</strong>: Jun. 2023</p>
</div>
