---
weight: 1
title: "Prueba de una muestra con t de Student"
output: html_document
aliases: /one-sample-t-test/
---



<p>Una de las pruebas de hipótesis más simples en estadística consiste en evaluar si un parámetro único obtenido de una muestra de mediciones difiere de un parámetro poblacional hipotético. La prueba busca determinar la probabilidad de obtener esa muestra a partir de una población con ciertas propiedades.</p>
<p>Para esto, utilizamos una prueba de una muestra con <em>t</em> de Student. La estadística de prueba, <em>t</em>, tiene la siguiente forma general:</p>
<p><span class="math display">\[t = \frac{St-\theta}{S_{St}}\]</span></p>
<p>Donde <em>St</em> es el valor de la estadística de tu muestra, <span class="math inline">\(\theta\)</span> es el valor poblacional con el que estás comparando tu muestra, y <span class="math inline">\(S_{St}\)</span> es el error estándar de tu estadística de muestra.</p>
<p>Estas pruebas se pueden utilizar para una variedad de parámetros muestreados de poblaciones (por ejemplo, medias, pendientes e interceptos en regresión lineal, etc.). Aquí, veamos un ejemplo sencillo en el que probamos si la media de un conjunto de medidas replicadas difiere de un valor hipotético.</p>
<p><img src="One_sample_t_test_image.png" /></p>
<p>Imagina que un científico forense intentaba rastrear el origen de algunas muestras de suelo tomadas de huellas en una escena del crimen. Recogió 10 muestras y analizó la concentración de polen de una especie de pino que se encuentra en un bosque local. Se sabía que el suelo de ese bosque local tenía una concentración promedio de 125 granos por gramo de suelo. La prueba de <em>t</em> de una muestra probará la probabilidad de que las diez muestras provengan de ese bosque al comparar la concentración promedio en las diez nuevas muestras con el valor esperado si provinieran de ese bosque.</p>
<p>La estadística de prueba, <em>t</em>, es:</p>
<p><span class="math display">\[t = \frac{\bar{x}-\mu}{SE}\]</span></p>
<p>donde <span class="math inline">\(\bar{x}\)</span> es la media de la muestra, <span class="math inline">\(\mu\)</span> es la media poblacional y <em>SE</em> es el error estándar de la muestra.</p>
<p>Ten en cuenta que el tamaño de la estadística de prueba depende de dos cosas: 1) qué tan diferente es la media de la muestra de la media poblacional (el numerador) y 2) cuánta variación está presente dentro de la muestra (el denominador). La hipótesis nula es que la media poblacional de la cual se tomó la muestra es el valor conocido, es decir, <span class="math inline">\(H_o: \mu=125\)</span>.</p>
<div id="ejecutando-el-análisis" class="section level3">
<h3>Ejecutando el análisis</h3>
<p>La estadística de prueba <em>t</em> es relativamente sencilla de calcular manualmente. Luego, puedes comparar la estadística de prueba con una distribución <em>t</em> para determinar la probabilidad de obtener ese valor de la estadística de prueba si la hipótesis nula es verdadera.</p>
<p>Para calcular la probabilidad asociada a un valor dado de <em>t</em> en R, usa</p>
<pre class="r"><code>pt(q, df = your.df, lower.tail = FALSE) * 2</code></pre>
<p>donde <em>q</em> es tu valor de <em>t</em>, <em>your.df</em> son los grados de libertad (<em>n</em>-1). El <code>lower.tail = FALSE</code> asegura que estás calculando la probabilidad de obtener un valor de <em>t</em> más grande que el tuyo (es decir, la cola superior, P[X &gt; x]). Ten en cuenta que el valor crítico para <span class="math inline">\(t_{\alpha = 0.05}\)</span> varía según el número de grados de libertad: a mayor número de grados de libertad, menor es el valor crítico de <em>t</em>.</p>
<p>Es mucho más fácil utilizar la función <code>t.test</code> en R para obtener la estadística de prueba y su probabilidad asociada en una sola salida. Para una prueba de <em>t</em> de una muestra, usaríamos:</p>
<pre class="r"><code>t.test(y, mu = your.mu)</code></pre>
<p>donde <em>y</em> es un vector con tus datos de muestra y <em>your.mu</em> es el parámetro de la población con el que estás comparando la muestra.</p>
<p>En nuestro ejemplo de la escena del crimen, podríamos asignar nuestras diez mediciones a un objeto llamado “polen” y ejecutar el test de <em>t</em> en ese objeto.</p>
<pre class="r"><code>pollen &lt;- c(94, 135, 78, 98, 137, 114, 114, 101, 112, 121)
t.test(pollen, mu = 125)</code></pre>
</div>
<div id="interpretación-de-los-resultados" class="section level3">
<h3>Interpretación de los resultados</h3>
<pre><code>## 
## 	One Sample t-test
## 
## data:  pollen
## t = -3.0691, df = 9, p-value = 0.01337
## alternative hypothesis: true mean is not equal to 125
## 95 percent confidence interval:
##   97.20685 120.79315
## sample estimates:
## mean of x 
##       109</code></pre>
<p>La salida de una prueba <em>t</em> de una muestra es fácil de interpretar. En la salida anterior, la estadística de prueba <em>t</em> es -3.0691 con 9 grados de libertad, y un valor de <em>p</em> bajo (<em>p</em> = 0.013). Por lo tanto, podemos rechazar la hipótesis nula y concluir que es poco probable que las muestras de suelo de la escena del crimen provengan del bosque de pinos cercano.</p>
<p>También se obtiene la media de la muestra (109) y el intervalo de confianza del 95% para la media de la población estimada a partir de esa muestra (este no se superpondrá con la media hipotetizada cuando la prueba sea significativa).</p>
</div>
<div id="supuestos-a-verificar" class="section level3">
<h3>Supuestos a verificar</h3>
<p>Las pruebas <em>t</em> son pruebas paramétricas, lo que implica que podemos especificar una distribución de probabilidad para la población de la variable de la cual se tomaron las muestras. Las pruebas paramétricas (y no paramétricas) tienen varios supuestos. Si se violan estos supuestos, no podemos estar seguros de que la estadística de prueba siga una distribución <em>t</em>, en cuyo caso los valores de <em>p</em> pueden ser inexactos.</p>
<p><strong>Normalidad</strong>. La distribución <em>t</em> describe parámetros muestreados de una población normal, por lo que asume que los datos tienen una distribución normal. Sin embargo, hay que tener en cuenta que las pruebas <em>t</em> son bastante robustas ante violaciones de la normalidad (aunque hay que tener cuidado con la influencia de los valores atípicos).</p>
<p><strong>Independencia</strong>. Las observaciones deben haber sido muestreadas al azar de una población definida para que la media de la muestra sea una estimación imparcial de la media de la población. Si los datos individuales están vinculados de alguna manera, se violará el supuesto de independencia.</p>
</div>
<div id="comunicación-de-los-resultados" class="section level3">
<h3>Comunicación de los resultados</h3>
<p><strong>Escrito.</strong> Como mínimo, se debe informar la estadística de prueba <em>t</em> observada, el valor de <em>p</em> y el número de grados de libertad. Por ejemplo, se podría escribir “La media del recuento de polen de las huellas (109) fue significativamente más baja de lo esperado si proviniera del bosque cercano con un recuento promedio de 125 (<em>t</em> = 3.07, df = 9, P = 0.01)”.</p>
<p><strong>Visual.</strong> Los diagramas de caja o histogramas de frecuencia se pueden utilizar para visualizar la variación en una sola variable. En este ejemplo, se podría utilizar una línea o una flecha para indicar el valor único (125) con el que se estaba comparando la muestra.</p>
<pre class="r"><code>hist(pollen, xlab = &quot;Pollen count&quot;, main = NULL)
abline(v = 125, col = &quot;red&quot;)</code></pre>
<p><img src="/Statistics/t-tests/one-sample-t-test/_index_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<pre class="r"><code>boxplot(pollen, xlab = &quot;Pollen count&quot;, horizontal = TRUE)
abline(v = 125, col = &quot;red&quot;)</code></pre>
<p><img src="/Statistics/t-tests/one-sample-t-test/_index_files/figure-html/unnamed-chunk-5-2.png" width="672" /></p>
</div>
<div id="más-ayuda" class="section level3">
<h3>Más ayuda</h3>
<p>Escribe <code>?t.test</code> para obtener la ayuda de R sobre esta función.</p>
<p style="margin-left:.5in;text-indent:-.5in">
Quinn and Keough (2002) **Experimental design and data analysis for biologists*. Cambridge University Press. Capítulo 3: Prueba de hipótesis.
</p>
<p style="margin-left:.5in;text-indent:-.5in">
McKillup (2012) <em>Statistics explained. An introductory guide for life scientists.</em> Cambridge University Press. Capítulo 9: Comparación de las medias de una y dos muestras de datos distribuidos normalmente.
</p>
<p><strong>Autor</strong>: Alistair Poore</p>
<p><strong>Año</strong>: 2016</p>
<p><strong>Última actualización</strong>: Jun. 2023</p>
</div>
